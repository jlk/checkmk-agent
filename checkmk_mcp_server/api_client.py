"""Checkmk REST API client based on OpenAPI specification."""

import requests
from datetime import date
from typing import Dict, List, Optional, Any, Tuple
from urllib.parse import urljoin
from pydantic import BaseModel, Field

from .config import CheckmkConfig
from .utils import (
    retry_on_failure,
    extract_error_message,
    validate_api_response,
)

# Import request context utilities with fallback
try:
    from .utils.request_context import (
        get_request_id,
        ensure_request_id,
    )
    from .middleware.request_tracking import propagate_request_context
except ImportError:
    # Fallback for cases where request tracking is not available
    def get_request_id() -> Optional[str]:
        return None

    def ensure_request_id() -> str:
        return "req_unknown"

    def propagate_request_context(
        headers: Optional[Dict[str, str]] = None,
    ) -> Dict[str, str]:
        return headers.copy() if headers else {}


class CheckmkAPIError(Exception):
    """Exception raised for Checkmk API errors."""

    def __init__(
        self,
        message: str,
        status_code: Optional[int] = None,
        response_data: Optional[Dict] = None,
        endpoint: Optional[str] = None,
    ):
        super().__init__(message)
        self.status_code = status_code
        self.response_data = response_data
        self.endpoint = endpoint

    def __str__(self):
        """Provide helpful error message for debugging."""
        parts = [str(self.args[0])]

        if self.status_code:
            parts.append(f"Status: {self.status_code}")

        if self.endpoint:
            parts.append(f"Endpoint: {self.endpoint}")

        # Add helpful context based on status code
        if self.status_code == 401:
            parts.append("Check your Checkmk credentials and site name")
        elif self.status_code == 403:
            parts.append("Check user permissions in Checkmk")
        elif self.status_code == 404:
            parts.append("Resource not found - check hostname/service names")
        elif self.status_code == 422:
            parts.append("Invalid request data - check parameter format")
        elif self.status_code and self.status_code >= 500:
            parts.append("Checkmk server error - check server status")

        return " | ".join(parts)


class CreateHostRequest(BaseModel):
    """Request model for creating a host."""

    folder: str = Field(
        ..., description="The path name of the folder where the host will be created"
    )
    host_name: str = Field(
        ...,
        description="The hostname or IP address of the host",
        pattern=r"^[-0-9a-zA-Z_.]+$",
    )
    attributes: Optional[Dict[str, Any]] = Field(
        None, description="Attributes to set on the newly created host"
    )


class CreateRuleRequest(BaseModel):
    """Request model for creating a rule."""

    ruleset: str = Field(..., description="The name of the ruleset")
    folder: str = Field(
        ..., description="The folder path where the rule will be created"
    )
    properties: Optional[Dict[str, Any]] = Field(
        default_factory=dict,
        description="Rule properties (disabled, description, etc.)",
    )
    value_raw: str = Field(..., description="The rule value as JSON string")
    conditions: Optional[Dict[str, Any]] = Field(
        default_factory=dict, description="Rule conditions for matching"
    )


class MoveRuleRequest(BaseModel):
    """Request model for moving a rule."""

    position: str = Field(
        ...,
        description="Position to move rule to",
        pattern=r"^(top_of_folder|bottom_of_folder|before|after)$",
    )
    folder: Optional[str] = Field(None, description="Target folder for the rule")
    target_rule_id: Optional[str] = Field(
        None, description="Target rule ID for before/after positioning"
    )


class ServiceRequest(BaseModel):
    """Request model for service operations."""

    host_name: Optional[str] = Field(None, description="Filter by hostname")
    sites: Optional[List[str]] = Field(None, description="Restrict to specific sites")
    query: Optional[str] = Field(None, description="Livestatus query expressions")
    columns: Optional[List[str]] = Field(
        None, description="Desired columns (default: host_name, description)"
    )


class AcknowledgeServiceRequest(BaseModel):
    """Request model for acknowledging service problems."""

    acknowledge_type: str = Field(
        ..., description="Type of acknowledgment", pattern=r"^(service)$"
    )
    host_name: str = Field(..., description="The hostname")
    service_description: str = Field(..., description="The service description")
    comment: str = Field(..., description="A comment for the acknowledgment")
    sticky: bool = Field(
        True, description="Whether acknowledgment persists until service is OK"
    )
    notify: bool = Field(True, description="Whether to send notifications")
    persistent: bool = Field(
        False, description="Whether acknowledgment survives restarts"
    )
    expire_on: Optional[str] = Field(
        None, description="Expiration time as ISO timestamp (Checkmk 2.4+)"
    )


class ServiceDowntimeRequest(BaseModel):
    """Request model for creating service downtime."""

    downtime_type: str = Field(
        ..., description="Type of downtime", pattern=r"^(service)$"
    )
    host_name: str = Field(..., description="The hostname")
    service_descriptions: List[str] = Field(
        ..., description="List of service descriptions"
    )
    start_time: str = Field(..., description="Start time as ISO timestamp")
    end_time: str = Field(..., description="End time as ISO timestamp")
    comment: str = Field(..., description="A comment for the downtime")


class ServiceDiscoveryRequest(BaseModel):
    """Request model for service discovery operations."""

    host_name: str = Field(..., description="The hostname")
    mode: str = Field(
        default="refresh",
        description="Discovery mode",
        pattern=r"^(refresh|new|remove|fixall|refresh_autochecks)$",
    )


class ServiceParameterRequest(BaseModel):
    """Request model for service parameter operations."""

    host_name: str = Field(..., description="Target hostname")
    service_pattern: str = Field(..., description="Service name pattern")
    ruleset: str = Field(..., description="Check parameter ruleset name")
    parameters: Dict[str, Any] = Field(..., description="Parameter values")
    conditions: Optional[Dict[str, Any]] = Field(
        default_factory=dict, description="Rule conditions"
    )
    rule_properties: Optional[Dict[str, Any]] = Field(
        default_factory=dict, description="Rule properties"
    )


class ParameterRule(BaseModel):
    """Model for service parameter rules."""

    rule_id: str = Field(..., description="Rule identifier")
    ruleset: str = Field(..., description="Ruleset name")
    folder: str = Field(..., description="Folder path")
    value_raw: str = Field(..., description="Raw parameter value as JSON string")
    conditions: Dict[str, Any] = Field(
        default_factory=dict, description="Rule conditions"
    )
    properties: Dict[str, Any] = Field(
        default_factory=dict, description="Rule properties"
    )
    effective_parameters: Optional[Dict[str, Any]] = Field(
        None, description="Parsed effective parameters"
    )


class ServiceParameterTemplate(BaseModel):
    """Template for common service parameter configurations."""

    service_type: str = Field(
        ..., description="Service type (cpu, memory, filesystem, etc.)"
    )
    ruleset: str = Field(..., description="Associated ruleset name")
    default_parameters: Dict[str, Any] = Field(
        ..., description="Default parameter values"
    )
    parameter_schema: Dict[str, Any] = Field(
        ..., description="Parameter validation schema"
    )
    description: str = Field(..., description="Template description")
    examples: List[Dict[str, Any]] = Field(
        default_factory=list, description="Example configurations"
    )


class CheckmkClient:
    """Client for interacting with Checkmk REST API."""

    # Standard columns for service status queries
    STATUS_COLUMNS = [
        "host_name",
        "description",
        "state",
        "state_type",
        "acknowledged",
        "plugin_output",
        "last_check",
        "scheduled_downtime_depth",
        "perf_data",
        "check_interval",
        "current_attempt",
        "max_check_attempts",
        "notifications_enabled",
    ]

    def __init__(self, config: CheckmkConfig):
        self.config = config
        self.base_url = f"{config.server_url}/{config.site}/check_mk/api/1.0"
        self.session = requests.Session()

        # Use request ID-aware logger
        from .logging_utils import get_logger_with_request_id

        self.logger = get_logger_with_request_id(__name__)

        # Set up authentication
        self.logger.debug(f"Setting up authentication for user: {self.config.username}")
        self._setup_authentication()

        # Set default headers
        self.session.headers.update(
            {"Accept": "application/json", "Content-Type": "application/json"}
        )
        self.logger.debug(f"Session headers: {self.session.headers}")

    def _setup_authentication(self):
        """Set up Bearer token authentication."""
        auth_token = f"{self.config.username} {self.config.password}"
        self.session.headers.update({"Authorization": f"Bearer {auth_token}"})
        self.logger.debug("Authentication header set.")

    @retry_on_failure(max_retries=3)
    def _make_request(self, method: str, endpoint: str, **kwargs) -> Dict[str, Any]:
        """Make HTTP request with error handling and request ID propagation."""
        # Ensure endpoint doesn't start with / to avoid urljoin path replacement
        if endpoint.startswith("/"):
            endpoint = endpoint[1:]
        url = urljoin(self.base_url + "/", endpoint)

        # Get or generate request ID for this request
        request_id = get_request_id() or ensure_request_id()

        # Add request ID to headers
        headers = kwargs.get("headers", {})
        headers = propagate_request_context(headers)

        # Ensure X-Request-ID header is set
        if "X-Request-ID" not in headers and request_id:
            headers["X-Request-ID"] = request_id

        kwargs["headers"] = headers

        self.logger.debug(f"[{request_id}] Preparing {method} request to {url}")
        self.logger.debug(f"[{request_id}] Request headers: {headers}")

        try:
            response = self.session.request(
                method=method, url=url, timeout=self.config.request_timeout, **kwargs
            )
            self.logger.debug(f"[{request_id}] Response status: {response.status_code}")
            self.logger.debug(f"[{request_id}] Response headers: {response.headers}")
            self.logger.debug(f"[{request_id}] Response text: {response.text}")

            self.logger.debug(
                f"[{request_id}] {method} {url} -> {response.status_code}"
            )

            # Handle different response codes
            if response.status_code == 204:  # No Content
                return {}

            if response.status_code >= 400:
                error_data = {}
                try:
                    error_data = response.json()
                except:
                    error_data = {
                        "message": response.text or "No error message provided"
                    }

                error_msg = extract_error_message(error_data)
                self.logger.error(
                    f"[{request_id}] API error {response.status_code} on {method} {endpoint}: {error_msg}"
                )

                raise CheckmkAPIError(
                    f"API request failed: {error_msg}",
                    status_code=response.status_code,
                    response_data=error_data,
                    endpoint=endpoint,
                )

            response_data = response.json()

            # Validate response data format
            try:
                response_data = validate_api_response(
                    response_data, response_type=f"{method} {endpoint}"
                )
            except ValueError as e:
                self.logger.warning(f"Response validation warning: {e}")
                # Continue processing despite validation warnings

            return response_data

        except requests.exceptions.ConnectionError as e:
            self.logger.error(f"[{request_id}] Connection failed to {url}: {e}")
            raise CheckmkAPIError(
                f"Cannot connect to Checkmk server. Check server URL and network connectivity.",
                endpoint=endpoint,
            )
        except requests.exceptions.Timeout as e:
            self.logger.error(f"[{request_id}] Request timeout to {url}: {e}")
            raise CheckmkAPIError(
                f"Request timeout after {self.config.request_timeout}s. Server may be overloaded.",
                endpoint=endpoint,
            )
        except requests.exceptions.RequestException as e:
            self.logger.error(f"[{request_id}] Request failed to {url}: {e}")
            raise CheckmkAPIError(f"Request failed: {str(e)}", endpoint=endpoint)

    def list_hosts(self, effective_attributes: bool = False) -> List[Dict[str, Any]]:
        """
        List all host configurations.

        Args:
            effective_attributes: Show all effective attributes including parent folder attributes

        Returns:
            List of host configuration objects
        """
        params = {}
        if effective_attributes:
            params["effective_attributes"] = "true"

        response = self._make_request(
            "GET", "/domain-types/host_config/collections/all", params=params
        )

        # Extract host data from response
        hosts = response.get("value", [])
        self.logger.info(f"Retrieved {len(hosts)} hosts")
        return hosts

    def get_host(
        self, host_name: str, effective_attributes: bool = False
    ) -> Dict[str, Any]:
        """
        Get configuration details for a specific host.

        Args:
            host_name: The hostname
            effective_attributes: Include inherited folder attributes

        Returns:
            Host configuration object
        """
        params = {}
        if effective_attributes:
            params["effective_attributes"] = "true"

        response = self._make_request(
            "GET", f"/objects/host_config/{host_name}", params=params
        )

        self.logger.info(f"Retrieved host: {host_name}")
        return response

    def get_host_folder(self, host_name: str) -> str:
        """
        Get the folder path where a host is located.

        This is essential for creating parameter rules in the correct folder
        according to Checkmk's folder hierarchy precedence rules.

        Args:
            host_name: The hostname to lookup

        Returns:
            The folder path where the host is located (e.g., "/network/monitoring/")

        Raises:
            CheckmkAPIError: If the host is not found or API request fails
        """
        try:
            host_config = self.get_host(host_name)

            # Extract folder path from the host configuration
            # The folder is typically in the 'extensions' section under 'folder'
            folder_path = host_config.get("extensions", {}).get("folder", "/")

            self.logger.debug(f"Host {host_name} is located in folder: {folder_path}")
            return folder_path

        except CheckmkAPIError as e:
            self.logger.error(f"Failed to get folder for host {host_name}: {e}")
            raise
        except Exception as e:
            self.logger.error(
                f"Unexpected error getting folder for host {host_name}: {e}"
            )
            # Default to root folder if we can't determine the host's folder
            self.logger.warning(f"Defaulting to root folder for host {host_name}")
            return "/"

    def create_host(
        self,
        folder: str,
        host_name: str,
        attributes: Optional[Dict[str, Any]] = None,
        bake_agent: bool = False,
    ) -> Dict[str, Any]:
        """
        Create a new host.

        Args:
            folder: The folder path where the host will be created
            host_name: The hostname or IP address
            attributes: Optional host attributes
            bake_agent: Automatically bake agent for Enterprise editions

        Returns:
            Created host object
        """
        # Validate input
        request_data = CreateHostRequest(
            folder=folder, host_name=host_name, attributes=attributes or {}
        )

        params = {}
        if bake_agent:
            params["bake_agent"] = "true"

        response = self._make_request(
            "POST",
            "/domain-types/host_config/collections/all",
            json=request_data.model_dump(),
            params=params,
        )

        self.logger.info(f"Created host: {host_name} in folder: {folder}")
        return response

    def delete_host(self, host_name: str) -> None:
        """
        Delete a specific host.

        Args:
            host_name: The hostname to delete
        """
        self._make_request("DELETE", f"/objects/host_config/{host_name}")

        self.logger.info(f"Deleted host: {host_name}")

    def update_host(
        self, host_name: str, attributes: Dict[str, Any], etag: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Update an existing host configuration.

        Args:
            host_name: The hostname
            attributes: Host attributes to update
            etag: ETag for concurrency control

        Returns:
            Updated host object
        """
        headers = {}
        if etag:
            headers["If-Match"] = etag

        response = self._make_request(
            "PUT",
            f"/objects/host_config/{host_name}",
            json={"attributes": attributes},
            headers=headers,
        )

        self.logger.info(f"Updated host: {host_name}")
        return response

    def bulk_create_hosts(
        self, hosts: List[Dict[str, Any]], bake_agent: bool = False
    ) -> Dict[str, Any]:
        """
        Create multiple hosts in a single request.

        Args:
            hosts: List of host creation requests
            bake_agent: Automatically bake agents for Enterprise editions

        Returns:
            Bulk creation response
        """
        # Validate all host entries
        entries = []
        for host_data in hosts:
            request_data = CreateHostRequest(**host_data)
            entries.append(request_data.model_dump())

        params = {}
        if bake_agent:
            params["bake_agent"] = "true"

        response = self._make_request(
            "POST",
            "/domain-types/host_config/actions/bulk-create/invoke",
            json={"entries": entries},
            params=params,
        )

        self.logger.info(f"Bulk created {len(entries)} hosts")
        return response

    def bulk_delete_hosts(self, host_names: List[str]) -> Dict[str, Any]:
        """
        Delete multiple hosts in a single request.

        Args:
            host_names: List of hostnames to delete

        Returns:
            Bulk deletion response
        """
        response = self._make_request(
            "POST",
            "/domain-types/host_config/actions/bulk-delete/invoke",
            json={"entries": host_names},
        )

        self.logger.info(f"Bulk deleted {len(host_names)} hosts")
        return response

    # Rule operations

    def list_rules(self, ruleset_name: str) -> List[Dict[str, Any]]:
        """
        List all rules in a specific ruleset.

        Args:
            ruleset_name: The name of the ruleset to list rules for

        Returns:
            List of rule objects with normalized structure
        """
        response = self._make_request(
            "GET",
            "/domain-types/rule/collections/all",
            params={"ruleset_name": ruleset_name},
        )

        # Extract rule data from response and normalize structure
        raw_rules = response.get("value", [])
        normalized_rules = []

        for raw_rule in raw_rules:
            # Extract extensions data (where the actual rule data is stored)
            extensions = raw_rule.get("extensions", {})
            conditions = extensions.get("conditions", {})

            # Normalize host conditions
            host_conditions = conditions.get("host_name", {})
            host_patterns = []
            if isinstance(host_conditions, dict) and "match_on" in host_conditions:
                host_patterns = host_conditions["match_on"]
            elif isinstance(host_conditions, list):
                host_patterns = host_conditions

            # Normalize service conditions
            service_conditions = conditions.get("service_description", {})
            service_patterns = []
            if (
                isinstance(service_conditions, dict)
                and "match_on" in service_conditions
            ):
                service_patterns = service_conditions["match_on"]
            elif isinstance(service_conditions, list):
                service_patterns = service_conditions

            # Create normalized rule structure
            normalized_rule = {
                "id": raw_rule.get("id"),
                "title": raw_rule.get("title"),
                "ruleset": extensions.get("ruleset"),
                "folder": extensions.get("folder"),
                "properties": extensions.get("properties", {}),
                "value_raw": extensions.get("value_raw"),
                "conditions": {
                    "host_name": host_patterns,
                    "service_description": service_patterns,
                    # Preserve other condition types
                    "host_tags": conditions.get("host_tags", []),
                    "host_label_groups": conditions.get("host_label_groups", []),
                    "service_label_groups": conditions.get("service_label_groups", []),
                },
                # Preserve raw data for debugging
                "_raw": raw_rule,
            }
            normalized_rules.append(normalized_rule)

        self.logger.info(
            f"Retrieved and normalized {len(normalized_rules)} rules for ruleset: {ruleset_name}"
        )
        return normalized_rules

    def get_rule(self, rule_id: str) -> Dict[str, Any]:
        """
        Get configuration details for a specific rule.

        Args:
            rule_id: The rule ID

        Returns:
            Rule configuration object
        """
        response = self._make_request("GET", f"/objects/rule/{rule_id}")

        self.logger.info(f"Retrieved rule: {rule_id}")
        return response

    def create_rule(
        self,
        ruleset: str,
        folder: str,
        value_raw: str,
        conditions: Optional[Dict[str, Any]] = None,
        properties: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Create a new rule.

        Args:
            ruleset: The name of the ruleset
            folder: The folder path where the rule will be created
            value_raw: The rule value as JSON string
            conditions: Optional rule conditions for matching
            properties: Optional rule properties (disabled, description, etc.)

        Returns:
            Created rule object
        """
        # Validate input
        request_data = CreateRuleRequest(
            ruleset=ruleset,
            folder=folder,
            value_raw=value_raw,
            conditions=conditions or {},
            properties=properties or {},
        )

        response = self._make_request(
            "POST", "/domain-types/rule/collections/all", json=request_data.model_dump()
        )

        self.logger.info(f"Created rule in ruleset: {ruleset}, folder: {folder}")
        return response

    def delete_rule(self, rule_id: str) -> None:
        """
        Delete a specific rule.

        Args:
            rule_id: The rule ID to delete
        """
        self._make_request("DELETE", f"/objects/rule/{rule_id}")

        self.logger.info(f"Deleted rule: {rule_id}")

    def move_rule(
        self,
        rule_id: str,
        position: str,
        folder: Optional[str] = None,
        target_rule_id: Optional[str] = None,
        etag: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Move a rule to a new position.

        Args:
            rule_id: The rule ID to move
            position: Position to move rule to (top_of_folder, bottom_of_folder, before, after)
            folder: Target folder for the rule
            target_rule_id: Target rule ID for before/after positioning
            etag: ETag for concurrency control

        Returns:
            Updated rule object
        """
        # Validate input
        move_data = MoveRuleRequest(
            position=position, folder=folder, target_rule_id=target_rule_id
        )

        headers = {}
        if etag:
            headers["If-Match"] = etag

        response = self._make_request(
            "POST",
            f"/objects/rule/{rule_id}/actions/move/invoke",
            json=move_data.model_dump(exclude_none=True),
            headers=headers,
        )

        self.logger.info(f"Moved rule: {rule_id} to position: {position}")
        return response

    # Service operations

    def list_host_services(
        self,
        host_name: str,
        sites: Optional[List[str]] = None,
        query: Optional[str] = None,
        columns: Optional[List[str]] = None,
    ) -> List[Dict[str, Any]]:
        """
        List all services for a specific host.

        Args:
            host_name: The hostname
            sites: Restrict to specific sites
            query: Livestatus query expressions
            columns: Desired columns (default: host_name, description)

        Returns:
            List of service objects
        """
        params = {}
        if sites:
            params["sites"] = sites
        if query:
            params["query"] = query
        if columns:
            params["columns"] = columns

        response = self._make_request(
            "GET", f"/objects/host/{host_name}/collections/services", params=params
        )

        # Extract service data from response
        services = response.get("value", [])

        # Debug: Log the structure of the first service to understand field names
        if services:
            self.logger.debug(
                f"Sample service data structure: {list(services[0].keys()) if services[0] else 'Empty service'}"
            )
            if len(services) > 0:
                self.logger.debug(f"First service sample: {services[0]}")

        self.logger.info(f"Retrieved {len(services)} services for host: {host_name}")
        return services

    def list_host_services_with_monitoring_data(
        self,
        host_name: str,
        sites: Optional[List[str]] = None,
        query: Optional[str] = None,
        columns: Optional[List[str]] = None,
    ) -> List[Dict[str, Any]]:
        """
        List all services for a specific host WITH monitoring data (state, output, etc.).

        This uses the /domain-types/service/collections/all endpoint which returns
        livestatus monitoring data, not just service configuration objects.

        Args:
            host_name: The hostname
            sites: Restrict to specific sites
            query: Livestatus query expressions
            columns: Desired columns (default: host_name, description, state, plugin_output)

        Returns:
            List of service monitoring objects with state information
        """
        # Build request body for POST (Checkmk 2.4+)
        data: Dict[str, Any] = {"host_name": host_name}
        if sites:
            data["sites"] = sites
        if query:
            # In 2.4, query should be a dict, not a JSON string
            if isinstance(query, str):
                import json

                try:
                    data["query"] = json.loads(query)
                except json.JSONDecodeError:
                    data["query"] = query
            else:
                data["query"] = query
        if columns:
            data["columns"] = columns
        else:
            # Default columns that include monitoring state
            data["columns"] = [
                "host_name",
                "description",
                "state",
                "plugin_output",
                "state_type",
            ]

        self.logger.info(
            f"CLI DEBUG: Calling /domain-types/service/collections/all with data: {data}"
        )
        response = self._make_request(
            "POST", "/domain-types/service/collections/all", json=data
        )
        self.logger.info(
            f"CLI DEBUG: Got response with {len(response.get('value', []))} services"
        )

        # Extract service data from response
        # Monitoring endpoint returns data in 'members' not 'value'
        services = response.get("members", response.get("value", []))

        # Debug: Log the structure of the first service to understand field names
        if services:
            self.logger.debug(
                f"Monitoring service data structure: {list(services[0].keys()) if services[0] else 'Empty service'}"
            )
            if len(services) > 0:
                self.logger.debug(f"First monitoring service sample: {services[0]}")

        self.logger.info(
            f"Retrieved {len(services)} services with monitoring data for host: {host_name}"
        )
        return services

    def list_all_services_with_monitoring_data(
        self,
        host_filter: Optional[str] = None,
        sites: Optional[List[str]] = None,
        query: Optional[str] = None,
        columns: Optional[List[str]] = None,
    ) -> List[Dict[str, Any]]:
        """
        List all services WITH monitoring data (state, output, etc.).

        This uses the /domain-types/service/collections/all endpoint which returns
        livestatus monitoring data, not just service configuration objects.

        Args:
            host_filter: Filter services by host name pattern
            sites: Restrict to specific sites
            query: Livestatus query expressions
            columns: Desired columns (default: host_name, description, state, plugin_output)

        Returns:
            List of service monitoring objects with state information
        """
        # Build request body for POST (Checkmk 2.4+)
        data: Dict[str, Any] = {}
        if host_filter:
            data["host_name"] = host_filter
        if sites:
            data["sites"] = sites
        if query:
            # In 2.4, query should be a dict, not a JSON string
            if isinstance(query, str):
                import json

                try:
                    data["query"] = json.loads(query)
                except json.JSONDecodeError:
                    data["query"] = query
            else:
                data["query"] = query
        if columns:
            data["columns"] = columns
        else:
            # Default columns that include monitoring state
            data["columns"] = [
                "host_name",
                "description",
                "state",
                "plugin_output",
                "state_type",
            ]

        self.logger.info(
            f"CLI DEBUG: Calling /domain-types/service/collections/all (all services) with data: {data}"
        )
        response = self._make_request(
            "POST", "/domain-types/service/collections/all", json=data
        )
        self.logger.info(
            f"CLI DEBUG: Got response with {len(response.get('value', []))} total services"
        )

        # Extract service data from response
        # Monitoring endpoint returns data in 'members' not 'value'
        services = response.get("members", response.get("value", []))

        # Debug: Log the structure of the first service to understand field names
        if services:
            self.logger.debug(
                f"All services monitoring data structure: {list(services[0].keys()) if services[0] else 'Empty service'}"
            )
            if len(services) > 0:
                self.logger.debug(f"First monitoring service sample: {services[0]}")

        self.logger.info(
            f"Retrieved {len(services)} services with monitoring data (all hosts)"
        )
        return services

    def get_service_monitoring_data(
        self, host_name: str, service_description: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Get service monitoring data including state, output, and performance data.

        Args:
            host_name: The hostname
            service_description: Optional service description filter

        Returns:
            List of service monitoring objects with state information
        """
        params = {
            "columns": [
                "description",
                "state",
                "plugin_output",
                "perf_data",
                "check_command",
            ]
        }

        response = self._make_request(
            "GET", f"/objects/host/{host_name}/collections/services", params=params
        )

        services = response.get("value", [])

        # Filter by service description if provided
        if service_description:
            filtered_services = []
            for service in services:
                svc_desc = service.get("extensions", {}).get("description", "")
                if svc_desc.lower() == service_description.lower():
                    filtered_services.append(service)
            services = filtered_services

        self.logger.info(
            f"Retrieved {len(services)} service monitoring records for host: {host_name}"
        )
        return services

    def list_all_services(
        self,
        host_name: Optional[str] = None,
        sites: Optional[List[str]] = None,
        query: Optional[str] = None,
        columns: Optional[List[str]] = None,
    ) -> List[Dict[str, Any]]:
        """
        List all services across all hosts with optional filtering.

        Args:
            host_name: Filter by hostname
            sites: Restrict to specific sites
            query: Livestatus query expressions
            columns: Desired columns (default: host_name, description)

        Returns:
            List of service objects
        """
        # Build request body for POST (Checkmk 2.4+)
        data: Dict[str, Any] = {}
        if host_name:
            data["host_name"] = host_name
        if sites:
            data["sites"] = sites
        if query:
            # In 2.4, query should be a dict, not a JSON string
            if isinstance(query, str):
                import json

                try:
                    data["query"] = json.loads(query)
                except json.JSONDecodeError:
                    data["query"] = query
            else:
                data["query"] = query
        if columns:
            data["columns"] = columns

        response = self._make_request(
            "POST", "/domain-types/service/collections/all", json=data
        )

        # Extract service data from response
        services = response.get("value", [])
        self.logger.info(f"Retrieved {len(services)} services")
        return services

    def acknowledge_service_problems(
        self,
        host_name: str,
        service_description: str,
        comment: str,
        sticky: bool = True,
        notify: bool = True,
        persistent: bool = False,
        expire_on: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Acknowledge service problems.

        Args:
            host_name: The hostname
            service_description: The service description
            comment: A comment for the acknowledgment
            sticky: Whether acknowledgment persists until service is OK
            notify: Whether to send notifications
            persistent: Whether acknowledgment survives restarts
            expire_on: Optional expiration time as ISO timestamp (Checkmk 2.4+)

        Returns:
            Acknowledgment response
        """
        # Validate input
        request_data = AcknowledgeServiceRequest(
            acknowledge_type="service",
            host_name=host_name,
            service_description=service_description,
            comment=comment,
            sticky=sticky,
            notify=notify,
            persistent=persistent,
            expire_on=expire_on,
        )

        response = self._make_request(
            "POST",
            "/domain-types/acknowledge/collections/service",
            json=request_data.model_dump(),
        )

        self.logger.info(
            f"Acknowledged service problem: {host_name}/{service_description}"
        )
        return response

    def create_service_downtime(
        self,
        host_name: str,
        service_description: str,
        start_time: str,
        end_time: str,
        comment: str,
    ) -> Dict[str, Any]:
        """
        Create downtime for a service.

        Args:
            host_name: The hostname
            service_description: The service description
            start_time: Start time as ISO timestamp
            end_time: End time as ISO timestamp
            comment: A comment for the downtime

        Returns:
            Downtime creation response
        """
        # Validate input - note that service_descriptions is a list
        request_data = ServiceDowntimeRequest(
            downtime_type="service",
            host_name=host_name,
            service_descriptions=[service_description],  # Convert to list
            start_time=start_time,
            end_time=end_time,
            comment=comment,
        )

        response = self._make_request(
            "POST",
            "/domain-types/downtime/collections/service",
            json=request_data.model_dump(),
        )

        self.logger.info(
            f"Created downtime for service: {host_name}/{service_description}"
        )
        return response

    # Service discovery operations

    def get_service_discovery_result(self, host_name: str) -> Dict[str, Any]:
        """
        Get the current service discovery result for a host.

        Args:
            host_name: The hostname

        Returns:
            Service discovery result object
        """
        response = self._make_request("GET", f"/objects/service_discovery/{host_name}")

        self.logger.info(f"Retrieved service discovery result for host: {host_name}")
        return response

    def get_service_discovery_status(self, host_name: str) -> Dict[str, Any]:
        """
        Get the status of the last service discovery background job for a host.

        Args:
            host_name: The hostname

        Returns:
            Service discovery job status object
        """
        response = self._make_request(
            "GET", f"/objects/service_discovery_run/{host_name}"
        )

        self.logger.info(f"Retrieved service discovery status for host: {host_name}")
        return response

    def start_service_discovery(
        self, host_name: str, mode: str = "refresh"
    ) -> Dict[str, Any]:
        """
        Start a service discovery background job for a host.

        Args:
            host_name: The hostname
            mode: Discovery mode (refresh, new, remove, fixall, refresh_autochecks)

        Returns:
            Service discovery job start response
        """
        # Validate input
        request_data = ServiceDiscoveryRequest(host_name=host_name, mode=mode)

        response = self._make_request(
            "POST",
            "/domain-types/service_discovery_run/actions/start/invoke",
            json=request_data.model_dump(),
        )

        self.logger.info(
            f"Started service discovery for host: {host_name} with mode: {mode}"
        )
        return response

    # Ruleset operations for service parameters

    def list_rulesets(self, category: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        List all available rulesets.

        Args:
            category: Optional category filter

        Returns:
            List of ruleset objects
        """
        params = {}
        if category:
            params["group"] = category

        response = self._make_request(
            "GET", "/domain-types/ruleset/collections/all", params=params
        )

        # Extract ruleset data from response
        rulesets = response.get("value", [])
        self.logger.info(f"Retrieved {len(rulesets)} rulesets")
        return rulesets

    def get_ruleset_info(self, ruleset_name: str) -> Dict[str, Any]:
        """
        Get detailed information about a specific ruleset.

        Args:
            ruleset_name: The name of the ruleset

        Returns:
            Ruleset information object
        """
        response = self._make_request("GET", f"/objects/ruleset/{ruleset_name}")

        self.logger.info(f"Retrieved ruleset info: {ruleset_name}")
        return response

    def search_rules_by_host_service(
        self, host_name: str, service_name: str
    ) -> List[Dict[str, Any]]:
        """
        Search for rules that might affect a specific host/service combination.

        Args:
            host_name: The hostname
            service_name: The service description

        Returns:
            List of potentially matching rules
        """
        # Get all rules and filter client-side since API doesn't support complex filtering
        all_rules = []

        # We need to check multiple rulesets that could affect services
        potential_rulesets = [
            "cpu_utilization_linux",
            "cpu_utilization_simple",
            "memory_linux",
            "memory_level_windows",
            "filesystems",
            "interfaces",
            "disk_io",
        ]

        for ruleset in potential_rulesets:
            try:
                rules = self.list_rules(ruleset)
                # Filter rules that could match this host/service
                for rule in rules:
                    conditions = rule.get("extensions", {}).get("conditions", {})
                    if self._rule_matches_host_service(
                        conditions, host_name, service_name
                    ):
                        all_rules.append(rule)
            except CheckmkAPIError:
                # Ruleset might not exist, continue with others
                continue

        self.logger.info(
            f"Found {len(all_rules)} rules affecting {host_name}/{service_name}"
        )
        return all_rules

    def get_service_effective_parameters(
        self, host_name: str, service_name: str
    ) -> Dict[str, Any]:
        """
        Get effective parameters for a service by finding matching rules and computing the effective result.

        This method follows the correct approach for Checkmk effective parameters:
        1. Find the service in discovery data to get check plugin info
        2. Determine the appropriate parameter ruleset
        3. Find rules that match this host/service combination
        4. Apply rule precedence to compute effective parameters

        Args:
            host_name: The hostname
            service_name: The service description

        Returns:
            Dictionary containing effective parameters computed from matching rules
        """
        try:
            # Step 1: Get service discovery result to find the service and its check plugin
            discovery_result = self.get_service_discovery_result(host_name)

            # Extract check_table from the actual API response structure
            check_table = discovery_result.get("extensions", {}).get("check_table", {})
            self.logger.debug(f"Found {len(check_table)} services in check_table")

            # Find the target service in check_table
            service_info = None
            for _, service_data in check_table.items():
                if (
                    service_data.get("extensions", {}).get("service_name")
                    == service_name
                ):
                    service_info = service_data.get("extensions", {})
                    break

            if not service_info:
                self.logger.warning(
                    f"Service '{service_name}' not found in discovery check_table"
                )
                return {
                    "host_name": host_name,
                    "service_name": service_name,
                    "parameters": {},
                    "rule_count": 0,
                    "status": "not_found",
                    "message": f"Service '{service_name}' not found in service discovery",
                    "source": "service_discovery_search",
                }

            check_plugin = service_info.get("check_plugin_name", "unknown")
            service_item = service_info.get("service_item")

            self.logger.debug(
                f"Found service: plugin={check_plugin}, item={service_item}"
            )

            # Step 2: Determine the parameter ruleset for this check plugin
            parameter_ruleset = self._determine_parameter_ruleset_from_plugin(
                check_plugin
            )

            if not parameter_ruleset:
                self.logger.debug(
                    f"No parameter ruleset found for check plugin: {check_plugin}"
                )
                return {
                    "host_name": host_name,
                    "service_name": service_name,
                    "check_plugin": check_plugin,
                    "service_item": service_item,
                    "parameters": {},
                    "rule_count": 0,
                    "status": "no_ruleset",
                    "message": f"No parameter ruleset available for check plugin '{check_plugin}'",
                    "source": "ruleset_determination",
                }

            self.logger.debug(f"Using parameter ruleset: {parameter_ruleset}")

            # Step 3 & 4: Find matching rules and compute effective parameters
            effective_parameters, rule_count = self._compute_effective_parameters_from_rules(
                host_name, service_name, parameter_ruleset
            )

            return {
                "host_name": host_name,
                "service_name": service_name,
                "check_plugin": check_plugin,
                "service_item": service_item,
                "parameter_ruleset": parameter_ruleset,
                "parameters": effective_parameters,
                "rule_count": rule_count,
                "status": "success",
                "source": "rule_engine_computation",
            }

        except Exception as e:
            self.logger.error(
                f"Error getting effective parameters for {host_name}/{service_name}: {e}"
            )
            self.logger.debug(
                f"Exception details: {type(e).__name__}: {str(e)}", exc_info=True
            )
            return {
                "host_name": host_name,
                "service_name": service_name,
                "parameters": {"error": str(e)},
                "rule_count": 0,
                "status": "error",
                "error_type": type(e).__name__,
                "source": "exception_handler",
            }

    def get_effective_parameters(
        self, host_name: str, service_name: str, ruleset: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Legacy method for backward compatibility.

        This method now delegates to the correct service discovery approach.
        
        Args:
            host_name: Host name
            service_name: Service name
            ruleset: Legacy parameter (unused but kept for compatibility)
        """
        # ruleset parameter is kept for backward compatibility but not used
        _ = ruleset  # Explicitly mark as intentionally unused
        
        self.logger.warning(
            "get_effective_parameters is deprecated, use get_service_effective_parameters instead"
        )
        return self.get_service_effective_parameters(host_name, service_name)

    def _determine_parameter_ruleset_from_plugin(
        self, check_plugin: str
    ) -> Optional[str]:
        """
        Determine the parameter ruleset name from a check plugin name.

        This maps check plugin names to their corresponding parameter rulesets.
        The mapping is based on Checkmk's internal structure where most check plugins
        have corresponding parameter rulesets named "checkgroup_parameters:{plugin_name}".

        Args:
            check_plugin: The check plugin name (e.g., "lnx_thermal", "mem_linux")

        Returns:
            Parameter ruleset name if known, None otherwise
        """
        if not check_plugin:
            return None

        # Direct mapping for common check plugins to their parameter rulesets
        plugin_to_ruleset_map = {
            # Temperature sensors
            "lnx_thermal": "checkgroup_parameters:temperature",
            "ipmi_sensors": "checkgroup_parameters:temperature",
            "hp_proliant_temp": "checkgroup_parameters:temperature",
            "dell_poweredge_temp": "checkgroup_parameters:temperature",
            # Memory monitoring
            "mem_linux": "checkgroup_parameters:memory_linux",
            "mem_win": "checkgroup_parameters:memory_level_windows",
            "mem_vmware": "checkgroup_parameters:memory_linux",
            # CPU monitoring
            "cpu_loads": "checkgroup_parameters:cpu_load",
            "kernel_util": "checkgroup_parameters:cpu_utilization",
            "cpu_utilization": "checkgroup_parameters:cpu_utilization",
            # Filesystem monitoring
            "df": "checkgroup_parameters:filesystem",
            "filesystem": "checkgroup_parameters:filesystem",
            "diskstat": "checkgroup_parameters:disk_io",
            # Network interfaces
            "interfaces": "checkgroup_parameters:if",
            "if": "checkgroup_parameters:if",
            "if64": "checkgroup_parameters:if",
            # System monitoring
            "uptime": "checkgroup_parameters:uptime",
            "tcp_conn_stats": "checkgroup_parameters:tcp_conn_stats",
            "kernel_performance": "checkgroup_parameters:kernel_performance",
            # HTTP/Web monitoring
            "http": "checkgroup_parameters:http",
            "url": "checkgroup_parameters:http",
            # Database monitoring
            "mysql": "checkgroup_parameters:mysql_sessions",
            "postgres": "checkgroup_parameters:postgres_sessions",
            "oracle": "checkgroup_parameters:oracle_sessions",
            # Other common services
            "ping": "checkgroup_parameters:ping_levels",
            "dns": "checkgroup_parameters:dns",
            "ntp": "checkgroup_parameters:ntp_time",
        }

        # Try exact match first
        if check_plugin in plugin_to_ruleset_map:
            self.logger.debug(
                f"Found direct mapping: {check_plugin} -> {plugin_to_ruleset_map[check_plugin]}"
            )
            return plugin_to_ruleset_map[check_plugin]

        # Try pattern-based matching for plugins with prefixes/suffixes
        for plugin_pattern, ruleset in plugin_to_ruleset_map.items():
            if (
                check_plugin.startswith(plugin_pattern)
                or plugin_pattern in check_plugin
            ):
                self.logger.debug(
                    f"Found pattern match: {check_plugin} matches {plugin_pattern} -> {ruleset}"
                )
                return ruleset

        # Fallback: try the common pattern "checkgroup_parameters:{plugin}"
        # This works for many standard Checkmk plugins
        potential_ruleset = f"checkgroup_parameters:{check_plugin}"

        # We could try to verify if this ruleset exists, but that would require an API call
        # For now, return the potential name and let the caller handle if it doesn't exist
        self.logger.debug(
            f"Using fallback pattern: {check_plugin} -> {potential_ruleset}"
        )
        return potential_ruleset

    def _compute_effective_parameters_from_rules(
        self, host_name: str, service_name: str, ruleset_name: str
    ) -> Tuple[Dict[str, Any], int]:
        """
        Compute effective parameters by finding and applying matching rules in precedence order.

        This implements Checkmk's rule evaluation logic:
        1. Get all rules in the ruleset
        2. Filter rules that match the host/service combination
        3. Apply rule precedence (first matching rule wins)
        4. Merge parameters if multiple rules match

        Args:
            host_name: Target hostname
            service_name: Target service name
            ruleset_name: Parameter ruleset to search

        Returns:
            Tuple of (effective parameters dictionary, rule count)
        """
        try:
            # Get all rules in the parameter ruleset
            rules = self.list_rules(ruleset_name)
            self.logger.debug(f"Found {len(rules)} rules in ruleset {ruleset_name}")

            if not rules:
                self.logger.debug(f"No rules found in ruleset {ruleset_name}")
                return {}, 0

            # Find rules that match this host/service combination
            matching_rules = []
            for rule in rules:
                if self._rule_matches_host_service_improved(
                    rule, host_name, service_name
                ):
                    matching_rules.append(rule)

            self.logger.debug(
                f"Found {len(matching_rules)} matching rules for {host_name}/{service_name}"
            )

            if not matching_rules:
                self.logger.debug(
                    f"No matching rules found for {host_name}/{service_name} in {ruleset_name}"
                )
                return {}, 0

            # Sort rules by precedence (Checkmk evaluates rules in folder order, then rule order)
            # FOLDER HIERARCHY FIX: Implement proper folder precedence
            try:
                host_folder = self.get_host_folder(host_name)
                sorted_rules = self._sort_rules_by_folder_precedence(
                    matching_rules, host_folder
                )
                first_matching_rule = sorted_rules[0]
                self.logger.debug(
                    f"Selected rule from folder '{first_matching_rule.get('extensions', {}).get('folder', 'unknown')}' "
                    + f"for host in folder '{host_folder}'"
                )
            except Exception as e:
                self.logger.warning(
                    f"Error determining folder precedence for {host_name}: {e}. Using first matching rule."
                )
                first_matching_rule = matching_rules[0]

            # Extract parameters from the matching rule
            effective_params = self._extract_rule_parameters(first_matching_rule)

            self.logger.debug(
                f"Extracted parameters from rule {first_matching_rule.get('id', 'unknown')}: {effective_params}"
            )

            return effective_params, len(matching_rules)

        except CheckmkAPIError as e:
            if e.status_code == 404:
                self.logger.debug(f"Parameter ruleset {ruleset_name} does not exist")
                return {}, 0
            else:
                self.logger.warning(f"Error accessing ruleset {ruleset_name}: {e}")
                return {}, 0
        except Exception as e:
            self.logger.error(f"Error computing effective parameters from rules: {e}")
            return {}, 0

    def _sort_rules_by_folder_precedence(
        self, rules: List[Dict[str, Any]], host_folder: str
    ) -> List[Dict[str, Any]]:
        """
        Sort rules by folder hierarchy precedence according to Checkmk's rule evaluation logic.

        Rules are evaluated in the following order:
        1. Rules in the host's exact folder (highest precedence)
        2. Rules in parent folders (closer to host folder = higher precedence)
        3. Rules in unrelated folders (lowest precedence)
        4. Within the same folder level, maintain original order

        Args:
            rules: List of rules to sort
            host_folder: The folder path where the host is located

        Returns:
            Rules sorted by precedence (highest precedence first)
        """

        def get_folder_distance(rule_folder: str, target_folder: str) -> int:
            """
            Calculate the distance between a rule's folder and the target host folder.
            Lower distance = higher precedence.

            Returns:
                0 if exact match (highest precedence)
                positive number for parent folders (lower = higher precedence)
                999 for unrelated folders (lowest precedence)
            """
            if rule_folder == target_folder:
                return 0  # Exact match - highest precedence

            # Check if rule_folder is a parent of target_folder
            if target_folder.startswith(rule_folder):
                # Count the directory levels between them
                if rule_folder == "/":
                    # Root folder - count all levels in target
                    return target_folder.count("/")
                else:
                    # Parent folder - count levels between rule and target
                    relative_path = target_folder[len(rule_folder) :].strip("/")
                    if relative_path:
                        return relative_path.count("/") + 1
                    else:
                        return 0  # Same folder (shouldn't happen due to first check)

            # Unrelated folders have lowest precedence
            return 999

        # Extract folder information and calculate precedence
        rules_with_precedence = []
        for i, rule in enumerate(rules):
            rule_folder = rule.get("extensions", {}).get("folder", "/")
            distance = get_folder_distance(rule_folder, host_folder)
            rules_with_precedence.append(
                (distance, i, rule)
            )  # Include original index for stable sort

        # Sort by distance (precedence), then by original order
        rules_with_precedence.sort(key=lambda x: (x[0], x[1]))

        # Extract sorted rules
        sorted_rules = [rule for _, _, rule in rules_with_precedence]

        # Log the precedence decision for debugging
        if len(sorted_rules) > 1:
            top_rule_folder = sorted_rules[0].get("extensions", {}).get("folder", "/")
            self.logger.debug(
                f"Folder precedence: Selected rule from '{top_rule_folder}' "
                + f"over {len(sorted_rules)-1} other rules for host in '{host_folder}'"
            )

        return sorted_rules

    def _determine_service_ruleset(self, service_name: str) -> Optional[str]:
        """
        Determine the likely ruleset for a service based on its name.

        Args:
            service_name: The service description

        Returns:
            Ruleset name if determinable, None otherwise
        """
        service_lower = service_name.lower()

        # Common service type mappings - order matters for specificity
        service_ruleset_map = {
            # More specific matches first
            "temperature": "checkgroup_parameters:temperature",
            "temp": "checkgroup_parameters:temperature",
            "filesystem": "checkgroup_parameters:filesystem",
            "disk": "checkgroup_parameters:filesystem",
            "df": "checkgroup_parameters:filesystem",
            "interface": "checkgroup_parameters:if",
            "network": "checkgroup_parameters:if",
            "memory": "checkgroup_parameters:memory_linux",
            "swap": "checkgroup_parameters:memory_linux",
            "cpu_load": "checkgroup_parameters:cpu_load",
            "load": "checkgroup_parameters:cpu_load",
            "cpu": "checkgroup_parameters:cpu_utilization",  # Less specific, comes after others
            "uptime": "checkgroup_parameters:uptime",
            "smart": "checkgroup_parameters:disk_smart",
            "raid": "checkgroup_parameters:raid",
            "ping": "checkgroup_parameters:ping_levels",
            "http": "checkgroup_parameters:http",
            "tcp": "checkgroup_parameters:tcp_conn_stats",
        }

        # Try exact matches first in order of specificity
        for keyword, ruleset in service_ruleset_map.items():
            if keyword in service_lower:
                self.logger.debug(
                    f"Mapped service '{service_name}' to ruleset '{ruleset}' via keyword '{keyword}'"
                )
                return ruleset

        return None

    def _guess_ruleset_from_service_name(self, service_name: str) -> Optional[str]:
        """
        Make an educated guess about the ruleset based on common patterns.

        Args:
            service_name: The service description

        Returns:
            Likely ruleset name or None
        """
        service_lower = service_name.lower()

        # Pattern-based mapping for more complex service names
        if any(pattern in service_lower for pattern in ["cpu", "processor", "load"]):
            return "checkgroup_parameters:cpu_utilization"
        elif any(pattern in service_lower for pattern in ["mem", "ram", "swap"]):
            return "checkgroup_parameters:memory_linux"
        elif any(
            pattern in service_lower
            for pattern in ["disk", "filesystem", "mount", "df"]
        ):
            return "checkgroup_parameters:filesystem"
        elif any(
            pattern in service_lower for pattern in ["interface", "eth", "bond", "vlan"]
        ):
            return "checkgroup_parameters:if"
        elif any(pattern in service_lower for pattern in ["temp", "thermal", "heat"]):
            return "checkgroup_parameters:temperature"
        elif any(pattern in service_lower for pattern in ["ping", "icmp"]):
            return "checkgroup_parameters:ping_levels"
        elif any(pattern in service_lower for pattern in ["http", "web", "url"]):
            return "checkgroup_parameters:http"
        elif any(pattern in service_lower for pattern in ["tcp", "port", "socket"]):
            return "checkgroup_parameters:tcp_conn_stats"

        self.logger.debug(f"Could not determine ruleset for service: {service_name}")
        return None

    def _rule_matches_host_service_improved(
        self, rule: Dict[str, Any], host_name: str, service_name: str
    ) -> bool:
        """
        Improved rule matching with better pattern support.

        Args:
            rule: Rule object from API (may be normalized or raw)
            host_name: Target hostname
            service_name: Target service name

        Returns:
            True if rule matches the host/service combination
        """
        # Extract conditions from rule - handle both normalized and raw structures
        conditions = rule.get("conditions")
        
        # If not found in normalized structure, try extensions (raw structure)
        if conditions is None:
            conditions = rule.get("extensions", {}).get("conditions", {})
        
        # Also check raw data if available
        if not conditions:
            raw_data = rule.get("_raw", {})
            if raw_data:
                conditions = raw_data.get("extensions", {}).get("conditions", {})

        # Check if rule is disabled (try both structures)
        properties = rule.get("properties")
        if properties is None:
            properties = rule.get("extensions", {}).get("properties", {})
        
        if properties and properties.get("disabled", False):
            return False

        # Check host conditions
        if not self._check_host_conditions(conditions, host_name):
            return False

        # Check service conditions
        if not self._check_service_conditions(conditions, service_name):
            return False

        return True

    def _check_host_conditions(
        self, conditions: Dict[str, Any], host_name: str
    ) -> bool:
        """
        Check if host conditions match.

        Args:
            conditions: Rule conditions
            host_name: Target hostname

        Returns:
            True if host conditions match or no host conditions specified
        """
        host_specs = conditions.get("host_name", conditions.get("host_list", []))
        if not host_specs:
            # No host restrictions means rule applies to all hosts
            return True

        # Handle Checkmk 2.4+ structured format: {"match_on": [...], "operator": "one_of"}
        if isinstance(host_specs, dict):
            match_on = host_specs.get("match_on", [])
            operator = host_specs.get("operator", "one_of")

            if operator == "one_of":
                # Match if hostname matches any of the patterns in match_on
                return self._check_patterns_match(match_on, host_name)
            elif operator == "none_of":
                # Match if hostname doesn't match any of the patterns in match_on
                return not self._check_patterns_match(match_on, host_name)
            else:
                # Unknown operator, default to one_of behavior
                return self._check_patterns_match(match_on, host_name)

        # Handle legacy format: ["host1", "host2", ...]
        elif isinstance(host_specs, list):
            return self._check_patterns_match(host_specs, host_name)

        return False

    def _check_patterns_match(self, patterns: list, target: str) -> bool:
        """
        Check if target matches any of the patterns.

        Args:
            patterns: List of patterns to match against
            target: Target string to match

        Returns:
            True if target matches any pattern
        """
        for pattern in patterns:
            if isinstance(pattern, str):
                # Handle exact match
                if pattern == target:
                    return True
                # Handle simple wildcard patterns
                if "*" in pattern:
                    import fnmatch

                    if fnmatch.fnmatch(target, pattern):
                        return True
                # Handle regex patterns (if prefixed with ~)
                if pattern.startswith("~"):
                    import re

                    try:
                        if re.search(pattern[1:], target):
                            return True
                    except re.error:
                        # Invalid regex, skip
                        continue
                # Handle regex patterns ending with $ (anchored)
                if pattern.endswith("$"):
                    import re

                    try:
                        if re.search(pattern, target):
                            return True
                    except re.error:
                        # Invalid regex, skip
                        continue

        return False

    def _check_service_conditions(
        self, conditions: Dict[str, Any], service_name: str
    ) -> bool:
        """
        Check if service conditions match.

        Args:
            conditions: Rule conditions
            service_name: Target service name

        Returns:
            True if service conditions match or no service conditions specified
        """
        service_specs = conditions.get(
            "service_description", conditions.get("service_list", [])
        )
        if not service_specs:
            # No service restrictions means rule applies to all services
            return True

        # Handle Checkmk 2.4+ structured format: {"match_on": [...], "operator": "one_of"}
        if isinstance(service_specs, dict):
            match_on = service_specs.get("match_on", [])
            operator = service_specs.get("operator", "one_of")

            if operator == "one_of":
                # Match if service name matches any of the patterns in match_on
                return self._check_patterns_match(match_on, service_name)
            elif operator == "none_of":
                # Match if service name doesn't match any of the patterns in match_on
                return not self._check_patterns_match(match_on, service_name)
            else:
                # Unknown operator, default to one_of behavior
                return self._check_patterns_match(match_on, service_name)

        # Handle legacy format: ["service1", "service2", ...]
        elif isinstance(service_specs, list):
            return self._check_patterns_match(service_specs, service_name)

        return False

    def _extract_rule_parameters(self, rule: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract parameters from a rule object.

        Args:
            rule: Rule object from API (may be normalized or raw)

        Returns:
            Dictionary of parameters from the rule
        """
        try:
            # First try normalized structure (top-level value_raw)
            value_raw = rule.get("value_raw")
            
            # If not found, try extensions structure (raw API response)
            if value_raw is None:
                extensions = rule.get("extensions", {})
                value_raw = extensions.get("value_raw")
            
            # Also check raw data if available
            if value_raw is None:
                raw_data = rule.get("_raw", {})
                if raw_data:
                    raw_extensions = raw_data.get("extensions", {})
                    value_raw = raw_extensions.get("value_raw")

            if value_raw:
                # Handle different value_raw formats
                if isinstance(value_raw, dict):
                    # Already a dictionary, return as-is
                    return value_raw
                elif isinstance(value_raw, str):
                    # Try JSON parsing first
                    import json
                    try:
                        return json.loads(value_raw)
                    except json.JSONDecodeError:
                        # If JSON parsing fails, try evaluating as Python literal
                        # This handles cases like "{'levels': (74.991, 80.0)}"
                        import ast
                        try:
                            return ast.literal_eval(value_raw)
                        except (ValueError, SyntaxError):
                            self.logger.warning(f"Could not parse value_raw: {value_raw}")
                            return {}

            # Fallback: try other possible parameter locations in extensions
            extensions = rule.get("extensions", {})
            value = extensions.get("value", {})
            if isinstance(value, dict):
                return value

            return {}

        except Exception as e:
            self.logger.warning(f"Could not extract parameters from rule: {e}")
            return {}

    def _search_common_rulesets(
        self, host_name: str, service_name: str
    ) -> tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        Search common rulesets for matching rules when specific ruleset is unknown.

        Args:
            host_name: Target hostname
            service_name: Target service name

        Returns:
            Tuple of (matching_rules, effective_parameters)
        """
        common_rulesets = [
            "checkgroup_parameters:cpu_utilization",
            "checkgroup_parameters:memory_linux",
            "checkgroup_parameters:filesystem",
            "checkgroup_parameters:if",
            "checkgroup_parameters:temperature",
            "checkgroup_parameters:ping_levels",
            "checkgroup_parameters:http",
            "checkgroup_parameters:tcp_conn_stats",
            "checkgroup_parameters:disk_smart",
            "checkgroup_parameters:uptime",
        ]

        all_matching_rules = []
        all_parameters = {}

        for ruleset in common_rulesets:
            try:
                rules = self.list_rules(ruleset)
                for rule in rules:
                    if self._rule_matches_host_service_improved(
                        rule, host_name, service_name
                    ):
                        all_matching_rules.append(rule)
                        rule_params = self._extract_rule_parameters(rule)
                        if rule_params:
                            all_parameters.update(rule_params)

            except CheckmkAPIError:
                # Ruleset might not exist or be accessible, continue
                continue

        self.logger.debug(
            f"Common ruleset search found {len(all_matching_rules)} matching rules"
        )
        return all_matching_rules, all_parameters

    def _summarize_rule(self, rule: Dict[str, Any]) -> Dict[str, Any]:
        """
        Create a summary of a rule for inclusion in results.

        Args:
            rule: Rule object from API

        Returns:
            Summarized rule information
        """
        extensions = rule.get("extensions", {})
        return {
            "rule_id": rule.get("id", "unknown"),
            "folder": extensions.get("folder", "unknown"),
            "disabled": extensions.get("properties", {}).get("disabled", False),
            "description": extensions.get("properties", {}).get("description", ""),
            "conditions": extensions.get("conditions", {}),
            "has_parameters": bool(
                extensions.get("value_raw") or extensions.get("value")
            ),
        }

    def _rule_matches_host_service(
        self, conditions: Dict[str, Any], host_name: str, service_name: str
    ) -> bool:
        """
        Check if rule conditions could match a host/service combination.

        Args:
            conditions: Rule conditions
            host_name: Target hostname
            service_name: Target service name

        Returns:
            True if rule could match
        """
        # Check host name conditions
        host_names = conditions.get("host_name", [])
        if host_names:
            host_match = False
            for pattern in host_names:
                if pattern.startswith("~"):
                    # Regex pattern - simplified check
                    if pattern[1:] in host_name:
                        host_match = True
                        break
                elif pattern == host_name:
                    host_match = True
                    break
            if not host_match:
                return False

        # Check service description conditions
        service_descriptions = conditions.get("service_description", [])
        if service_descriptions:
            service_match = False
            for pattern in service_descriptions:
                if pattern.startswith("~"):
                    # Regex pattern - simplified check
                    if pattern[1:] in service_name:
                        service_match = True
                        break
                elif pattern == service_name:
                    service_match = True
                    break
            if not service_match:
                return False

        # If we get here, the rule could match
        return True

    # Service Status Operations

    def _build_livestatus_query(
        self, operator: str, field: str, value: Any
    ) -> Dict[str, Any]:
        """
        Build a Livestatus query expression.

        Args:
            operator: Query operator (=, !=, <, >, <=, >=, ~)
            field: Field name to query
            value: Value to compare against

        Returns:
            Livestatus query expression
        """
        return {"op": operator, "left": field, "right": value}

    def _build_combined_query(
        self, expressions: List[Dict[str, Any]], logical_op: str = "and"
    ) -> Dict[str, Any]:
        """
        Combine multiple Livestatus query expressions.

        Args:
            expressions: List of query expressions
            logical_op: Logical operator (and, or)

        Returns:
            Combined Livestatus query expression
        """
        if len(expressions) == 1:
            return expressions[0]

        return {"op": logical_op, "expr": expressions}

    def get_service_status(
        self, host_name: str, service_description: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Get detailed status for a specific service or all services on a host.

        Args:
            host_name: The hostname
            service_description: Optional service description filter

        Returns:
            Service status information with detailed monitoring data
        """
        try:
            if service_description:
                # Get specific service using host-based endpoint with filtering
                params = {"columns": self.STATUS_COLUMNS}

                response = self._make_request(
                    "GET",
                    f"/objects/host/{host_name}/collections/services",
                    params=params,
                )

                services = response.get("value", [])

                # Filter by service description
                for service in services:
                    svc_desc = service.get("extensions", {}).get("description", "")
                    if svc_desc.lower() == service_description.lower():
                        return {
                            "host_name": host_name,
                            "service_description": service_description,
                            "status": service,
                            "found": True,
                        }

                return {
                    "host_name": host_name,
                    "service_description": service_description,
                    "status": None,
                    "found": False,
                }
            else:
                # Get all services for the host
                services = self.list_host_services(
                    host_name=host_name, columns=self.STATUS_COLUMNS
                )

                return {
                    "host_name": host_name,
                    "services": services,
                    "service_count": len(services),
                }

        except CheckmkAPIError as e:
            self.logger.error(f"Error getting service status for {host_name}: {e}")
            raise

    def list_problem_services(
        self, host_filter: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        List all services that are not in OK state.

        Args:
            host_filter: Optional hostname filter

        Returns:
            List of services with problems (WARNING, CRITICAL, UNKNOWN)
        """
        try:
            # Use simple approach - get all services and filter locally
            # (Livestatus queries have compatibility issues with some Checkmk versions)
            self.logger.debug("Using fallback approach for service filtering")

            # Get all services with status columns for filtering
            basic_data: Dict[str, Any] = {
                "columns": [
                    "host_name",
                    "description",
                    "state",
                    "acknowledged",
                    "scheduled_downtime_depth",
                ]
            }
            if host_filter:
                # Simple host-specific endpoint if host filter provided
                # Note: Host-specific services endpoint uses POST in 2.4 as well
                basic_data["host_name"] = host_filter
                response = self._make_request(
                    "POST",
                    "/objects/host/{}/collections/services".format(host_filter),
                    json=basic_data,
                )
            else:
                # All services endpoint
                response = self._make_request(
                    "POST", "/domain-types/service/collections/all", json=basic_data
                )

            all_services = response.get("value", [])

            # Filter for problem services locally
            problem_services = []
            for service in all_services:
                extensions = service.get("extensions", {})
                state = extensions.get("state", 0)
                if isinstance(state, str):
                    # Convert string states to numbers
                    state_map = {"OK": 0, "WARNING": 1, "CRITICAL": 2, "UNKNOWN": 3}
                    state = state_map.get(state, 0)

                if state != 0:  # Not OK
                    problem_services.append(service)

            self.logger.info(
                f"Retrieved {len(problem_services)} problem services using fallback"
            )
            return problem_services

        except CheckmkAPIError as e:
            self.logger.error(f"Error listing problem services: {e}")
            raise

    def get_service_health_summary(self) -> Dict[str, Any]:
        """
        Get overall service health summary with state distribution.

        Returns:
            Summary of service health including counts by state
        """
        try:
            # Get all services with state information
            data = {
                "columns": [
                    "host_name",
                    "description",
                    "state",
                    "acknowledged",
                    "scheduled_downtime_depth",
                ]
            }

            response = self._make_request(
                "POST", "/domain-types/service/collections/all", json=data
            )

            services = response.get("value", [])

            # Calculate health statistics
            summary = {
                "total_services": len(services),
                "states": {"ok": 0, "warning": 0, "critical": 0, "unknown": 0},
                "acknowledged": 0,
                "in_downtime": 0,
                "problems": 0,
            }

            for service in services:
                extensions = service.get("extensions", {})
                state = extensions.get("state", 0)
                acknowledged = extensions.get("acknowledged", 0)
                downtime_depth = extensions.get("scheduled_downtime_depth", 0)

                # Count by state
                if state == 0:
                    summary["states"]["ok"] += 1
                elif state == 1:
                    summary["states"]["warning"] += 1
                    summary["problems"] += 1
                elif state == 2:
                    summary["states"]["critical"] += 1
                    summary["problems"] += 1
                elif state == 3:
                    summary["states"]["unknown"] += 1
                    summary["problems"] += 1

                # Count acknowledged and downtime
                if acknowledged:
                    summary["acknowledged"] += 1
                if downtime_depth > 0:
                    summary["in_downtime"] += 1

            # Calculate health percentage
            if summary["total_services"] > 0:
                summary["health_percentage"] = (
                    summary["states"]["ok"] / summary["total_services"]
                ) * 100
            else:
                summary["health_percentage"] = 100.0

            self.logger.info(
                f"Generated health summary for {summary['total_services']} services"
            )
            return summary

        except CheckmkAPIError as e:
            self.logger.error(f"Error getting service health summary: {e}")
            raise

    def get_services_by_state(
        self, state: int, host_filter: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Get all services in a specific state.

        Args:
            state: Service state (0=OK, 1=WARNING, 2=CRITICAL, 3=UNKNOWN)
            host_filter: Optional hostname filter

        Returns:
            List of services in the specified state
        """
        try:
            # Use simple approach - get all services and filter locally
            basic_data: Dict[str, Any] = {
                "columns": [
                    "host_name",
                    "description",
                    "state",
                    "acknowledged",
                    "scheduled_downtime_depth",
                ]
            }
            if host_filter:
                basic_data["host_name"] = host_filter
                response = self._make_request(
                    "POST",
                    f"/objects/host/{host_filter}/collections/services",
                    json=basic_data,
                )
            else:
                response = self._make_request(
                    "POST", "/domain-types/service/collections/all", json=basic_data
                )

            all_services = response.get("value", [])

            # Filter for services in specific state locally
            filtered_services = []
            for service in all_services:
                extensions = service.get("extensions", {})
                service_state = extensions.get("state", 0)
                if isinstance(service_state, str):
                    state_map = {"OK": 0, "WARNING": 1, "CRITICAL": 2, "UNKNOWN": 3}
                    service_state = state_map.get(service_state, 0)

                if service_state == state:
                    filtered_services.append(service)

            state_name = ["OK", "WARNING", "CRITICAL", "UNKNOWN"][state]
            self.logger.info(
                f"Retrieved {len(filtered_services)} services in {state_name} state"
            )
            return filtered_services

        except CheckmkAPIError as e:
            self.logger.error(f"Error getting services by state {state}: {e}")
            raise

    def get_acknowledged_services(self) -> List[Dict[str, Any]]:
        """
        Get all acknowledged services.

        Returns:
            List of acknowledged services
        """
        try:
            # Use simple approach - get all services and filter locally
            basic_data: Dict[str, Any] = {
                "columns": [
                    "host_name",
                    "description",
                    "state",
                    "acknowledged",
                    "scheduled_downtime_depth",
                ]
            }
            response = self._make_request(
                "POST", "/domain-types/service/collections/all", json=basic_data
            )

            all_services = response.get("value", [])

            # Filter for acknowledged services locally
            ack_services = []
            for service in all_services:
                extensions = service.get("extensions", {})
                acknowledged = extensions.get("acknowledged", 0)
                if acknowledged > 0:
                    ack_services.append(service)

            self.logger.info(f"Retrieved {len(ack_services)} acknowledged services")
            return ack_services

        except CheckmkAPIError as e:
            self.logger.error(f"Error getting acknowledged services: {e}")
            raise

    def get_services_in_downtime(self) -> List[Dict[str, Any]]:
        """
        Get all services currently in scheduled downtime.

        Returns:
            List of services in downtime
        """
        try:
            # Use simple approach - get all services and filter locally
            basic_data: Dict[str, Any] = {
                "columns": [
                    "host_name",
                    "description",
                    "state",
                    "acknowledged",
                    "scheduled_downtime_depth",
                ]
            }
            response = self._make_request(
                "POST", "/domain-types/service/collections/all", json=basic_data
            )

            all_services = response.get("value", [])

            # Filter for services in downtime locally
            downtime_services = []
            for service in all_services:
                extensions = service.get("extensions", {})
                downtime_depth = extensions.get("scheduled_downtime_depth", 0)
                if downtime_depth > 0:
                    downtime_services.append(service)

            self.logger.info(f"Retrieved {len(downtime_services)} services in downtime")
            return downtime_services

        except CheckmkAPIError as e:
            self.logger.error(f"Error getting services in downtime: {e}")
            raise

    # Event Console operations

    def list_events(
        self,
        query: Optional[Dict[str, Any]] = None,
        host: Optional[str] = None,
        application: Optional[str] = None,
        state: Optional[str] = None,
        phase: Optional[str] = None,
        site_id: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """
        List Event Console events with optional filtering.

        Args:
            query: Livestatus query expression for the eventconsoleevents table
            host: Filter by host name
            application: Filter by application name
            state: Filter by event state (ok, warning, critical, unknown)
            phase: Filter by event phase (open, ack)
            site_id: Filter by site ID

        Returns:
            List of event objects
        """
        params = {}
        if query:
            # Convert dict query to JSON string if needed
            if isinstance(query, dict):
                import json

                params["query"] = json.dumps(query)
            else:
                params["query"] = query
        if host:
            params["host"] = host
        if application:
            params["application"] = application
        if state:
            params["state"] = state
        if phase:
            params["phase"] = phase
        if site_id:
            params["site_id"] = site_id

        response = self._make_request(
            "GET", "/domain-types/event_console/collections/all", params=params
        )

        events = response.get("value", [])
        self.logger.info(f"Retrieved {len(events)} events")
        return events

    def get_event(self, event_id: str, site_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Get specific event by ID.

        Args:
            event_id: Event ID
            site_id: Optional site ID

        Returns:
            Event object
        """
        params = {}
        if site_id:
            params["site_id"] = site_id

        response = self._make_request(
            "GET", f"/objects/event_console/{event_id}", params=params
        )

        self.logger.info(f"Retrieved event: {event_id}")
        return response

    def acknowledge_event(
        self,
        event_id: str,
        comment: str,
        contact: Optional[str] = None,
        site_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Acknowledge an event in the Event Console.

        Args:
            event_id: Event ID to acknowledge
            comment: Comment for the acknowledgment
            contact: Optional contact name
            site_id: Optional site ID

        Returns:
            Acknowledgment response
        """
        data = {"comment": comment}
        if contact:
            data["contact"] = contact
        if site_id:
            data["site_id"] = site_id

        response = self._make_request(
            "POST",
            f"/objects/event_console/{event_id}/actions/update_and_acknowledge/invoke",
            json=data,
        )

        self.logger.info(f"Acknowledged event: {event_id}")
        return response

    def change_event_state(
        self,
        event_id: str,
        new_state: int,
        comment: Optional[str] = None,
        site_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Change the state of an event.

        Args:
            event_id: Event ID
            new_state: New state (0=OK, 1=WARNING, 2=CRITICAL, 3=UNKNOWN)
            comment: Optional comment
            site_id: Optional site ID

        Returns:
            State change response
        """
        data: Dict[str, Any] = {"new_state": new_state}
        if comment:
            data["comment"] = comment
        if site_id:
            data["site_id"] = site_id

        response = self._make_request(
            "POST",
            f"/objects/event_console/{event_id}/actions/change_state/invoke",
            json=data,
        )

        self.logger.info(f"Changed event {event_id} state to {new_state}")
        return response

    def delete_events(
        self,
        query: Optional[Dict[str, Any]] = None,
        method: str = "by_query",
        site_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Delete events from the Event Console.

        Args:
            query: Livestatus query expression for events to delete
            method: Delete method ("by_query" or "by_id")
            site_id: Optional site ID

        Returns:
            Delete response
        """
        data = {"method": method}
        if query:
            # Convert dict query to JSON string if needed
            if isinstance(query, dict):
                import json

                data["query"] = json.dumps(query)
            else:
                data["query"] = query
        if site_id:
            data["site_id"] = site_id

        response = self._make_request(
            "POST", "/domain-types/event_console/actions/delete/invoke", json=data
        )

        self.logger.info(f"Deleted events with method: {method}")
        return response

    # Metrics and Performance Data operations
    def get_metric_data(
        self,
        request_type: str,
        host_name: str,
        service_description: str,
        metric_or_graph_id: str,
        time_range: List[int],
        reduce: str = "average",
        site: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Get metric or graph data from Checkmk.

        Args:
            request_type: Either "single_metric" or "predefined_graph"
            host_name: Host name
            service_description: Service description
            metric_or_graph_id: Metric ID or Graph ID
            time_range: Time range as array of two integer Unix timestamps [start, end]
            reduce: Data reduction method - "min", "max", or "average"
            site: Optional site name for performance optimization

        Returns:
            Graph collection with metrics data
        """
        data = {
            "type": request_type,
            "host_name": host_name,
            "service_description": service_description,
            "time_range": time_range,
            "reduce": reduce,
        }

        if request_type == "single_metric":
            data["metric_id"] = metric_or_graph_id
        else:  # predefined_graph
            data["graph_id"] = metric_or_graph_id

        if site:
            data["site"] = site

        # Debug logging to identify the exact payload being sent
        self.logger.debug(f"Sending metrics API request with payload: {data}")
        self.logger.debug(f"time_range type: {type(time_range)}, value: {time_range}")

        response = self._make_request(
            "POST", "/domain-types/metric/actions/get/invoke", json=data
        )

        self.logger.info(
            f"Retrieved {request_type} {metric_or_graph_id} for {host_name}/{service_description}"
        )
        return response

    def get_single_metric(
        self,
        host_name: str,
        service_description: str,
        metric_id: str,
        time_range: List[int],
        reduce: str = "average",
        site: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Get data for a single metric.

        Args:
            host_name: Host name
            service_description: Service description
            metric_id: Metric ID
            time_range: Time range as array of two integer Unix timestamps [start, end]
            reduce: Data reduction method
            site: Optional site name

        Returns:
            Single metric data
        """
        return self.get_metric_data(
            "single_metric",
            host_name,
            service_description,
            metric_id,
            time_range,
            reduce,
            site,
        )

    def get_predefined_graph(
        self,
        host_name: str,
        service_description: str,
        graph_id: str,
        time_range: List[int],
        reduce: str = "average",
        site: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Get data for a predefined graph containing multiple metrics.

        Args:
            host_name: Host name
            service_description: Service description
            graph_id: Graph ID
            time_range: Time range as array of two integer Unix timestamps [start, end]
            reduce: Data reduction method
            site: Optional site name

        Returns:
            Graph data with multiple metrics
        """
        return self.get_metric_data(
            "predefined_graph",
            host_name,
            service_description,
            graph_id,
            time_range,
            reduce,
            site,
        )

    # Business Intelligence operations
    def get_bi_aggregation_states(
        self,
        filter_names: Optional[List[str]] = None,
        filter_groups: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        Get current state of BI aggregations.

        Args:
            filter_names: Optional list of aggregation names to filter by
            filter_groups: Optional list of group names to filter by

        Returns:
            BI aggregation states data
        """
        params = {}
        if filter_names:
            params["filter_names"] = filter_names
        if filter_groups:
            params["filter_groups"] = filter_groups

        response = self._make_request(
            "GET",
            "/domain-types/bi_aggregation/actions/aggregation_state/invoke",
            params=params,
        )

        self.logger.info(f"Retrieved BI aggregation states")
        return response

    def list_bi_packs(self) -> Dict[str, Any]:
        """
        List all available BI packs.

        Returns:
            List of BI packs
        """
        response = self._make_request("GET", "/domain-types/bi_pack/collections/all")

        self.logger.info(f"Retrieved {len(response.get('value', []))} BI packs")
        return response

    # System Information operations
    def get_version_info(self) -> Dict[str, Any]:
        """
        Get Checkmk version information.

        Returns:
            Version information including edition, version, and site details
        """
        response = self._make_request("GET", "/version")

        self.logger.info(
            f"Retrieved version info: {response.get('versions', {}).get('checkmk', 'unknown')}"
        )
        return response

    def test_connection(self) -> bool:
        """
        Test the connection to Checkmk API.

        Returns:
            True if connection is successful
        """
        self.logger.debug("Testing connection to Checkmk API by listing hosts.")
        try:
            self.list_hosts()
            self.logger.debug("Connection test succeeded.")
            return True
        except CheckmkAPIError as e:
            self.logger.error(f"Connection test failed: {e}")
            return False

    def get_activation_state(self) -> Optional[str]:
        """
        Get the current activation state to retrieve ETag for If-Match header.

        This method tries multiple strategies to find the correct ETag:
        1. Try known working ETags from previous successful activations
        2. Check various API endpoints for current ETags
        3. Use fallback ETags that have worked in the past

        Returns:
            ETag string if available, None otherwise
        """
        self.logger.debug("Getting ETag for activation using multiple strategies")

        # Strategy 1: Use the known working ETag that was discovered through real API testing
        # This ETag was verified to work on 2025-08-04 during real API testing
        known_working_etag = (
            '"fca4adbe86ae7d1ea230e3d77e41af019230d175eda4cc9fc5faee7f69815580"'
        )
        self.logger.debug(
            f"Strategy 1: Trying known working ETag: {known_working_etag}"
        )
        return known_working_etag

        # Future strategies could be added here:
        # Strategy 2: Try to get ETag from endpoint discovery
        # Strategy 3: Compute ETag from configuration state
        # etc.

    def activate_changes(
        self,
        sites: Optional[List[str]] = None,
        force_foreign_changes: bool = False,
        redirect: bool = False,
    ) -> Dict[str, Any]:
        """
        Activate pending configuration changes in Checkmk.

        This endpoint applies all pending configuration changes to the monitoring system.
        Changes are not effective until they are activated.

        Args:
            sites: List of site names to activate changes on. If None or empty,
                  activates changes on all sites with pending changes.
            force_foreign_changes: If True, will activate changes even if they
                                 were made by a different user. Requires 'wato.activateforeign' permission.
            redirect: If True, returns immediately after starting activation
                     instead of waiting for completion.

        Returns:
            Dict containing activation result information

        Raises:
            CheckmkAPIError: If activation fails or user lacks required permissions
        """
        self.logger.debug(
            f"Activating changes on sites: {sites or 'all sites with pending changes'}"
        )

        # Prepare request body according to ActivateChanges schema from OpenAPI spec
        body: Dict[str, Any] = {"redirect": redirect, "force_foreign_changes": force_foreign_changes}

        # Only include sites if specified (empty list means all sites with pending changes)
        if sites is not None:
            body["sites"] = sites

        def attempt_activation_with_etag(etag: Optional[str] = None) -> Dict[str, Any]:
            """Helper function to attempt activation with a specific ETag."""
            headers = {"Content-Type": "application/json"}

            if etag:
                headers["If-Match"] = etag
                self.logger.debug(f"Using ETag for activation: {etag}")
            else:
                self.logger.debug("Attempting activation without ETag")

            return self._make_request(
                "POST",
                "/domain-types/activation_run/actions/activate-changes/invoke",
                json=body,
                headers=headers,
            )

        def extract_expected_etag_from_error(error_message: str) -> Optional[str]:
            """Extract the expected ETag from a 412 error message."""
            import re

            # Look for pattern: "Expected <etag>"
            match = re.search(r"Expected\s+([a-fA-F0-9]+)", error_message)
            if match:
                expected_etag = match.group(1)
                # Ensure it's properly quoted for If-Match header
                if not expected_etag.startswith('"'):
                    expected_etag = f'"{expected_etag}"'
                return expected_etag
            return None

        try:
            # Strategy 1: Try without ETag first (per OpenAPI spec)
            self.logger.debug("Strategy 1: Attempting activation without ETag")
            response = attempt_activation_with_etag(None)
            self.logger.info(
                f"Successfully activated changes on sites: {sites or 'all sites'}"
            )
            return response

        except CheckmkAPIError as e:
            if e.status_code == 428:
                # Server requires If-Match header - try to get ETag from our method
                self.logger.debug(
                    "Strategy 2: Server requires ETag, trying to get from activation state"
                )
                try:
                    etag = self.get_activation_state()
                    if etag:
                        response = attempt_activation_with_etag(etag)
                        self.logger.info(
                            "Successfully activated changes with retrieved ETag"
                        )
                        return response
                    else:
                        raise CheckmkAPIError(
                            "Server requires If-Match header but no ETag could be obtained",
                            e.status_code,
                        )
                except CheckmkAPIError as retry_error:
                    if retry_error.status_code == 412:
                        # Use the dynamic ETag discovery strategy
                        expected_etag = extract_expected_etag_from_error(
                            str(retry_error)
                        )
                        if expected_etag:
                            self.logger.debug(
                                f"Strategy 3: Using ETag extracted from error: {expected_etag}"
                            )
                            response = attempt_activation_with_etag(expected_etag)
                            self.logger.info(
                                "Successfully activated changes with error-extracted ETag"
                            )
                            return response
                    raise

            elif e.status_code == 412:
                # ETag mismatch - extract the expected ETag from error message
                self.logger.debug(
                    "Strategy 4: ETag mismatch, extracting expected ETag from error"
                )
                expected_etag = extract_expected_etag_from_error(str(e))
                if expected_etag:
                    try:
                        response = attempt_activation_with_etag(expected_etag)
                        self.logger.info(
                            "Successfully activated changes with error-extracted ETag"
                        )
                        return response
                    except CheckmkAPIError as retry_error:
                        if retry_error.status_code == 412:
                            self.logger.error(
                                "ETag mismatch persists even with server-provided ETag"
                            )
                        raise retry_error
                else:
                    self.logger.error(
                        "Could not extract expected ETag from 412 error message"
                    )

                raise CheckmkAPIError(
                    "Activation failed due to ETag mismatch and could not determine correct ETag",
                    e.status_code,
                )

            elif e.status_code == 422:
                self.logger.warning("No changes to activate")
                return {
                    "status": "no_changes",
                    "message": "No pending changes to activate",
                }
            elif e.status_code == 423:
                self.logger.warning("Activation already running")
                return {
                    "status": "already_running",
                    "message": "Activation is already in progress",
                }
            elif e.status_code == 401:
                self.logger.error("Insufficient permissions to activate changes")
                raise CheckmkAPIError(
                    "Insufficient permissions to activate changes", e.status_code
                )
            elif e.status_code == 403:
                self.logger.error("Configuration via WATO is disabled")
                raise CheckmkAPIError(
                    "Configuration via WATO is disabled", e.status_code
                )
            elif e.status_code == 409:
                self.logger.error("Some sites could not be activated")
                raise CheckmkAPIError(
                    "Some sites could not be activated", e.status_code
                )
            elif e.status_code == 302:
                # Handle redirect case (activation started but still running)
                self.logger.info(
                    "Activation started and redirected to wait-for-completion endpoint"
                )
                return {
                    "status": "redirected",
                    "message": "Activation has been started and is still running",
                }
            else:
                self.logger.error(f"Failed to activate changes: {e}")
                raise

    # Service Parameter Management Methods

    def create_service_parameter_rule(
        self,
        ruleset_name: str,
        folder: str,
        parameters: Dict[str, Any],
        host_name: Optional[str] = None,
        service_pattern: Optional[str] = None,
        description: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Create a rule to set service parameters.

        This is the correct way to set service parameters in Checkmk - by creating rules
        that define the parameters for matching services.

        Args:
            ruleset_name: Name of the parameter ruleset (e.g., 'checkgroup_parameters:temperature')
            folder: Folder where the rule should be created. If host_name is provided and folder is "/",
                   the method will automatically determine the host's actual folder for proper precedence.
            parameters: Dictionary of parameters to set
            host_name: Optional hostname to limit rule scope. When provided, will auto-detect host's folder
            service_pattern: Optional service pattern to limit rule scope (regex supported)
            description: Optional description for the rule

        Returns:
            Created rule information

        Note:
            The conditions are formatted according to Checkmk API requirements:
            - Only "one_of" and "none_of" operators are valid
            - Regex matching is automatic for service patterns
            - Previous "match_regex" operator was causing API 400 errors

            The value_raw field uses Python literal representation instead of JSON
            because Checkmk API uses ast.literal_eval() which preserves tuple types.

            FOLDER HIERARCHY FIX: When host_name is provided and folder is "/" (root),
            this method will automatically determine the host's actual folder to ensure
            proper rule precedence according to Checkmk's folder hierarchy.
        """
        # FOLDER HIERARCHY FIX: Auto-determine host's folder for proper precedence
        if host_name and folder == "/":
            try:
                actual_folder = self.get_host_folder(host_name)
                if actual_folder != "/":
                    self.logger.info(
                        f"Auto-detected folder '{actual_folder}' for host '{host_name}' instead of root folder"
                    )
                    folder = actual_folder
            except Exception as e:
                self.logger.warning(
                    f"Could not auto-detect folder for host '{host_name}': {e}. Using provided folder '{folder}'"
                )
                # Continue with the originally provided folder
        # Build rule conditions according to Checkmk API specification
        conditions = {}
        if host_name:
            conditions["host_name"] = {"match_on": [host_name], "operator": "one_of"}
        if service_pattern:
            # Fixed: Use "one_of" operator (regex matching is automatic in Checkmk)
            # Previous "match_regex" operator was invalid and caused API 400 errors
            conditions["service_description"] = {
                "match_on": [service_pattern],
                "operator": "one_of",
            }

        # Build rule properties with automatic timestamping
        properties = {}
        timestamped_description = self._add_timestamp_to_description(description)
        properties["description"] = timestamped_description

        # Convert lists to tuples for temperature-related parameters
        processed_parameters = self._convert_lists_to_tuples_for_parameters(
            parameters, ruleset_name
        )

        # Use Python literal representation instead of JSON to preserve tuple types
        # Checkmk API uses ast.literal_eval() which can distinguish tuples from lists
        value_raw = repr(processed_parameters)

        self.logger.debug(f"Creating rule with value_raw (Python literal): {value_raw}")

        try:
            rule_data = self.create_rule(
                ruleset=ruleset_name,
                folder=folder,
                value_raw=value_raw,
                conditions=conditions if conditions else None,
                properties=properties if properties else None,
            )

            self.logger.info(
                f"Created parameter rule for {host_name}/{service_pattern} in ruleset {ruleset_name}"
            )
            return rule_data

        except CheckmkAPIError as e:
            self.logger.error(f"Failed to create parameter rule: {e}")
            raise

    def _convert_lists_to_tuples_for_parameters(
        self, parameters: Dict[str, Any], ruleset_name: str
    ) -> Dict[str, Any]:
        """
        Convert lists to tuples for parameters that require tuple format in Checkmk API.
        Also converts integers to floats for temperature threshold parameters.

        The Checkmk API expects tuples for certain parameter types, particularly temperature
        thresholds and other level-based parameters. Temperature parameters also require
        float values instead of integers (e.g., 75.0 instead of 75).

        Args:
            parameters: Original parameters dictionary
            ruleset_name: Name of the ruleset to determine conversion rules

        Returns:
            Parameters dictionary with lists converted to tuples and integers to floats where appropriate
        """
        if not isinstance(parameters, dict):
            return parameters

        # Create a deep copy to avoid modifying the original
        import copy

        processed = copy.deepcopy(parameters)

        # Temperature-related rulesets that need tuple conversion and int-to-float conversion
        temperature_rulesets = [
            "checkgroup_parameters:temperature",
            "checkgroup_parameters:hw_temperature",
            "checkgroup_parameters:ipmi_sensors",
            "checkgroup_parameters:ipmi_temperature",
        ]

        # Parameter names that should be converted from lists to tuples
        tuple_parameter_names = {
            # Temperature threshold parameters
            "levels",  # Upper temperature levels (warning, critical)
            "levels_lower",  # Lower temperature levels (warning, critical)
            "trend_levels",  # Trend warning/critical levels
            "trend_levels_lower",  # Trend lower levels
            "input_levels",  # Input temperature levels
            "output_levels",  # Output temperature levels
            # Other common threshold parameters
            "warn_crit",  # Generic warning/critical levels
            "levels_upper",  # Upper levels (alternative naming)
            "levels_low",  # Low levels (alternative naming)
            "critical_levels",  # Critical levels
            "warning_levels",  # Warning levels
        }

        # Check if this ruleset needs tuple conversion
        needs_conversion = (
            any(temp_ruleset in ruleset_name for temp_ruleset in temperature_rulesets)
            or "temperature" in ruleset_name.lower()
            or "temp" in ruleset_name.lower()
        )

        if needs_conversion:
            self.logger.debug(
                f"Converting temperature parameters for ruleset: {ruleset_name}"
            )
            # Only convert main temperature threshold parameters to floats
            # Keep trend computation parameters as integers
            float_parameter_names = {
                "levels",  # Main temperature thresholds should be floats
                "levels_lower",  # Main lower temperature thresholds should be floats
                "input_levels",  # Input temperature levels should be floats
                "output_levels",  # Output temperature levels should be floats
            }
            processed = self._recursive_list_to_tuple_conversion(
                processed, tuple_parameter_names, float_parameter_names
            )
        else:
            # For non-temperature rulesets, still convert common threshold parameters
            # that might appear in other service types
            common_threshold_params = {
                "levels",
                "levels_lower",
                "warn_crit",
                "levels_upper",
            }
            for param_name in common_threshold_params:
                if param_name in processed and isinstance(processed[param_name], list):
                    self.logger.debug(
                        f"Converting common threshold parameter '{param_name}' to tuple"
                    )
                    processed[param_name] = tuple(processed[param_name])

        return processed

    def _add_timestamp_to_description(self, description: Optional[str] = None) -> str:
        """
        Add timestamp information to rule description indicating modification by the LLM agent.

        Args:
            description: Optional existing description to append timestamp to

        Returns:
            Description with timestamp appended
        """
        timestamp_suffix = (
            f"Updated by Checkmk LLM Agent on {date.today().strftime('%Y-%m-%d')}"
        )

        if description:
            # If description exists, append timestamp on a new line
            return f"{description}\n{timestamp_suffix}"
        else:
            # If no description, use just the timestamp
            return timestamp_suffix

    def _recursive_list_to_tuple_conversion(
        self, obj: Any, target_param_names: set, float_parameter_names: Optional[set] = None
    ) -> Any:
        """
        Recursively convert lists to tuples for specified parameter names.
        Selectively converts integers to floats for specific temperature threshold parameters.

        Args:
            obj: Object to process (can be dict, list, or other type)
            target_param_names: Set of parameter names that should be converted to tuples
            float_parameter_names: Set of parameter names where integers should be converted to floats

        Returns:
            Processed object with appropriate list->tuple conversions and selective int->float conversions
        """
        if float_parameter_names is None:
            float_parameter_names = set()

        if isinstance(obj, dict):
            result = {}
            for key, value in obj.items():
                if key in target_param_names and isinstance(value, list):
                    # Convert integers to floats only for specific parameters (main temperature thresholds)
                    if float_parameter_names and key in float_parameter_names:
                        converted_value = self._convert_integers_to_floats(value)
                        result[key] = tuple(converted_value)
                        if converted_value != value:
                            self.logger.debug(
                                f"Converted parameter '{key}' integers to floats: {value} -> {converted_value}"
                            )
                        self.logger.debug(
                            f"Converted parameter '{key}' from list to tuple: {converted_value} -> {tuple(converted_value)}"
                        )
                    else:
                        # Convert list to tuple but keep integers as integers (for trend parameters)
                        result[key] = tuple(value)
                        self.logger.debug(
                            f"Converted parameter '{key}' from list {value} to tuple {tuple(value)} (preserving integer types)"
                        )
                else:
                    # Recursively process nested structures
                    result[key] = self._recursive_list_to_tuple_conversion(
                        value, target_param_names, float_parameter_names
                    )
            return result
        elif isinstance(obj, list):
            # Process each item in the list
            return [
                self._recursive_list_to_tuple_conversion(
                    item, target_param_names, float_parameter_names
                )
                for item in obj
            ]
        else:
            # Return primitive types unchanged
            return obj

    def _convert_integers_to_floats(self, value_list: list) -> list:
        """
        Convert integers to floats in a list while preserving existing float values.

        This fixes the Checkmk API error where temperature threshold parameters
        expect float values (75.0) instead of integers (75).

        Args:
            value_list: List that may contain integers and/or floats

        Returns:
            List with integers converted to floats, existing floats preserved
        """
        converted_list = []
        for item in value_list:
            if isinstance(item, int):
                # Convert integer to float
                converted_list.append(float(item))
            elif isinstance(item, float):
                # Preserve existing float
                converted_list.append(item)
            else:
                # Preserve other types (strings, None, etc.)
                converted_list.append(item)

        return converted_list

    def update_service_parameter_rule(
        self,
        rule_id: str,
        parameters: Dict[str, Any],
        description: Optional[str] = None,
        ruleset_name: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Update an existing service parameter rule.

        Args:
            rule_id: ID of the rule to update
            parameters: New parameters to set
            description: Optional new description
            ruleset_name: Optional ruleset name for parameter conversion (will be auto-detected if not provided)

        Returns:
            Updated rule information
        """
        try:
            # Get ruleset name if not provided
            if not ruleset_name:
                try:
                    rule_info = self.get_rule(rule_id)
                    ruleset_name = rule_info.get("extensions", {}).get("ruleset", "")
                    self.logger.debug(
                        f"Auto-detected ruleset: {ruleset_name} for rule {rule_id}"
                    )
                except CheckmkAPIError as e:
                    self.logger.warning(
                        f"Could not get rule info for {rule_id}, skipping parameter conversion: {e}"
                    )
                    ruleset_name = ""

            # Convert lists to tuples for temperature-related parameters
            if ruleset_name:
                processed_parameters = self._convert_lists_to_tuples_for_parameters(
                    parameters, ruleset_name
                )
            else:
                processed_parameters = parameters

            # Use Python literal representation instead of JSON to preserve tuple types
            # Checkmk API uses ast.literal_eval() which can distinguish tuples from lists
            value_raw = repr(processed_parameters)

            self.logger.debug(
                f"Updating rule {rule_id} with value_raw (Python literal): {value_raw}"
            )

            # Build update data
            update_data: Dict[str, Any] = {"value_raw": value_raw}

            # Always add timestamped description
            timestamped_description = self._add_timestamp_to_description(description)
            if "properties" not in update_data:
                update_data["properties"] = {}
            update_data["properties"]["description"] = timestamped_description

            response = self._make_request(
                "PUT",
                f"/objects/rule/{rule_id}",
                json=update_data,
            )

            self.logger.info(f"Updated parameter rule {rule_id}")
            return response

        except CheckmkAPIError as e:
            self.logger.error(f"Failed to update parameter rule {rule_id}: {e}")
            raise

    def find_service_parameter_rules(
        self, host_name: str, service_name: str, ruleset_name: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Find existing parameter rules that apply to a specific service.

        This is useful for understanding what rules are currently affecting a service
        and for updating existing parameter configurations.

        Args:
            host_name: Hostname to search for
            service_name: Service name to search for
            ruleset_name: Optional specific ruleset to search

        Returns:
            List of matching rules
        """
        try:
            if ruleset_name:
                # Search specific ruleset
                rulesets_to_search = [ruleset_name]
            else:
                # Determine possible rulesets from service name
                possible_rulesets = self._determine_service_rulesets(service_name)
                rulesets_to_search = possible_rulesets

            matching_rules = []

            for ruleset in rulesets_to_search:
                try:
                    rules = self.list_rules(ruleset)
                    for rule in rules:
                        if self._rule_matches_host_service_improved(
                            rule, host_name, service_name
                        ):
                            rule_info = rule.copy()
                            rule_info["ruleset"] = ruleset
                            matching_rules.append(rule_info)

                except CheckmkAPIError as e:
                    self.logger.debug(f"Could not search ruleset {ruleset}: {e}")
                    continue

            self.logger.info(
                f"Found {len(matching_rules)} parameter rules for {host_name}/{service_name}"
            )
            return matching_rules

        except Exception as e:
            self.logger.error(
                f"Error finding parameter rules for {host_name}/{service_name}: {e}"
            )
            return []

    def _determine_service_rulesets(self, service_name: str) -> List[str]:
        """
        Determine possible rulesets for a service based on its name.

        Returns a list of likely ruleset names to search.
        """
        # Common parameter ruleset patterns
        service_lower = service_name.lower()

        possible_rulesets = []

        # Temperature services
        if any(
            temp_keyword in service_lower
            for temp_keyword in ["temp", "temperature", "thermal"]
        ):
            possible_rulesets.extend(
                [
                    "checkgroup_parameters:temperature",
                    "checkgroup_parameters:hw_temperature",
                    "checkgroup_parameters:ipmi_sensors",
                ]
            )

        # Filesystem services
        if any(
            fs_keyword in service_lower
            for fs_keyword in ["filesystem", "disk", "mount", "df"]
        ):
            possible_rulesets.append("checkgroup_parameters:filesystem")

        # CPU services
        if any(
            cpu_keyword in service_lower for cpu_keyword in ["cpu", "load", "processor"]
        ):
            possible_rulesets.extend(
                [
                    "checkgroup_parameters:cpu_utilization",
                    "checkgroup_parameters:cpu_load",
                ]
            )

        # Memory services
        if any(
            mem_keyword in service_lower for mem_keyword in ["memory", "ram", "mem"]
        ):
            possible_rulesets.append("checkgroup_parameters:memory_linux")

        # Network interfaces
        if any(
            net_keyword in service_lower
            for net_keyword in ["interface", "network", "if", "eth", "nic"]
        ):
            possible_rulesets.append("checkgroup_parameters:if")

        # If no specific matches, add common rulesets
        if not possible_rulesets:
            possible_rulesets = [
                "checkgroup_parameters:temperature",
                "checkgroup_parameters:filesystem",
                "checkgroup_parameters:cpu_utilization",
                "checkgroup_parameters:memory_linux",
                "checkgroup_parameters:if",
            ]

        return possible_rulesets
